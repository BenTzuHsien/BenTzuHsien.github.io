---
permalink: /
title: "Welcome !"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a master student in Robotics at the University of Minnesota, advised by [Prof. Karthik Desingh](https://karthikdesingh.com/) at the [Robotics Perception and Manipulation Lab](https://rpm-lab.github.io/). My long-term research goal is to develop learning-based **mobile manipulation** policies that enable robots to perform everyday tasks in human environments. To achieve this goal, my current research directions include:

- **Last-meter navigation**  
  Bridging the gap between navigation and manipulation by positioning robots precisely enough for downstream manipulation. My work focuses on learning navigation policies that enable manipulation policies to operate beyond stationary settings.

- **Data-efficient imitation learning for manipulation**  
  Improving the sample efficiency and generalization of learning-based manipulation policies. I study how manipulation policies can be trained with minimal supervision, such as a small number of demonstrations, while still generalizing robustly to unseen objects and environments.


### Background and Experience

I completed my undergraduate studies in Mechanical Engineering, which provided a strong foundation in the physical principles underlying robotic systems, including **dynamics, control, and state estimation**. During this time, I served as the software lead of an Autonomous Underwater Vehicle (AUV) student team, where I was responsible for the design and integration of the software stack spanning perception, estimation, control, and navigation. This role involved extensive work with **embedded systems** and low-level programming, and gave me hands-on experience deploying autonomous robotic systems in real-world operating conditions rather than purely simulated settings.

In my masterâ€™s studies in Robotics, I shifted my focus toward learning-based robotic systems. I initially concentrated on robot perception, particularly vision, through advanced coursework in Robot Vision and Computer Vision, where I implemented projects on **visual servoing** and **monocular visual SLAM**. Building on this perception foundation, my current research focuses on learning-based mobile manipulation, including developing mobility policies that enable manipulation beyond stationary settings and one-shot imitation learning policies for eye-in-hand robot configurations. Through this work, I aim to tightly integrate perception, navigation, and manipulation into unified policies that generalize under limited supervision and real-world uncertainty.

## Contact Me

Please feel free to reach out if you are interested in my work or would like to discuss potential research directions. I am always happy to chat about research ideas and collaborations that push the boundaries of robotics~
